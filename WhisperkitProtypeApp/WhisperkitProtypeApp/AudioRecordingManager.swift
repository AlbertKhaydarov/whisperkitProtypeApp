//
//  AudioRecordingManager.swift
//  WhisperkitProtypeApp
//
//  Created by AI Assistant on 21.10.2025.
//

import Foundation
import AVFoundation


// MARK: - AudioRecordingManager Delegate
protocol AudioRecordingManagerDelegate: AnyObject {
    func audioRecordingManager(_ manager: AudioRecordingManager, didStartRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didStopRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didProduceAudioFrames frames: [Float])
    func audioRecordingManager(_ manager: AudioRecordingManager, didFailWith error: Error)
}

/// –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç 16kHz PCM
/// Manager for audio recording and conversion to 16kHz PCM format
class AudioRecordingManager: NSObject {
    
    // MARK: - Properties
    private let audioEngine: AVAudioEngine
    private let audioConverter: AVAudioConverter?
    private var isRecording = false
    
    // MARK: - Delegate
    weak var delegate: AudioRecordingManagerDelegate?
    
    // MARK: - Initialization
    override init() {
        self.audioEngine = AVAudioEngine()
        self.audioConverter = nil
        super.init()
        // –ù–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –≤ init, –¥–µ–ª–∞–µ–º —ç—Ç–æ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∑–∞–ø–∏—Å–∏
    }
    
    // MARK: - Public Methods
    
    /// –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    /// Request microphone permission
    func requestMicrophonePermission() async -> Bool {
        #if os(iOS)
        return await withCheckedContinuation { continuation in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
        #else
        // –ù–∞ macOS —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        return true
        #endif
    }
    
    /// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏
    /// Configure audio session
    func configureAudioSession() async throws {
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        
        try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
        try audioSession.setActive(true)
        
        print("üé§ Audio session configured successfully")
        #else
        // –ù–∞ macOS –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        print("üé§ Audio session configured for macOS")
        #endif
    }
    
    /// –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
    /// Start recording
    func startRecording() async throws {
        guard !isRecording else {
            print("‚ö†Ô∏è Already recording")
            return
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
        guard await requestMicrophonePermission() else {
            throw AudioRecordingError.microphonePermissionDenied
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—é
        try await configureAudioSession()
        
        // –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
        if audioEngine.isRunning {
            audioEngine.stop()
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫ –ë–ï–ó tap
        setupAudioEngineWithoutTap()
        
        // –ó–∞–ø—É—Å–∫–∞–µ–º –¥–≤–∏–∂–æ–∫ —Å–Ω–∞—á–∞–ª–∞
        do {
            try audioEngine.start()
            print("üé§ Audio engine started")
        } catch {
            print("‚ùå Failed to start audio engine: \(error)")
            throw AudioRecordingError.audioEngineSetupFailed
        }
        
        // –¢–µ–ø–µ—Ä—å —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –¥–≤–∏–∂–∫–∞
        setupAudioTap()
        
        isRecording = true
        print("üé§ Recording started")
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStartRecording: true)
        }
    }
    
    /// –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
    /// Stop recording
    func stopRecording() async throws {
        guard isRecording else {
            print("‚ö†Ô∏è Not recording")
            return
        }
        
        // –£–¥–∞–ª—è–µ–º tap —Å –≤—Ö–æ–¥–Ω–æ–≥–æ —É–∑–ª–∞
        let inputNode = audioEngine.inputNode
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫
        audioEngine.stop()
        
        isRecording = false
        
        print("‚èπÔ∏è Recording stopped")
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStopRecording: true)
        }
    }
    
    /// –ü–∞—É–∑–∞ –∑–∞–ø–∏—Å–∏
    /// Pause recording
    func pauseRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        audioEngine.pause()
        print("‚è∏Ô∏è Recording paused")
    }
    
    /// –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏
    /// Resume recording
    func resumeRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        try audioEngine.start()
        print("‚ñ∂Ô∏è Recording resumed")
    }
    
    /// –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–∏—Å–∏
    /// Check recording status
    func isCurrentlyRecording() -> Bool {
        return isRecording
    }
    
    // MARK: - Private Methods
    
    private func setupAudioEngineWithoutTap() {
        // –ü—Ä–æ—Å—Ç–æ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –±–µ–∑ tap
        let inputNode = audioEngine.inputNode
        
        // –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ tap
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
        print("üé§ Audio engine prepared (without tap)")
    }
    
    private func setupAudioTap() {
        let inputNode = audioEngine.inputNode
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è tap
        let inputFormat = inputNode.outputFormat(forBus: 0)
        print("üé§ Input format: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount) channels")
        
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, time in
            self?.processAudioBuffer(buffer, time: time)
        }
        print("üé§ Audio tap installed successfully")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, time: AVAudioTime) {
        print("üîÑ –ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä: \(buffer.frameLength) —Ñ—Ä–µ–π–º–æ–≤, —Ñ–æ—Ä–º–∞—Ç: \(buffer.format)")
        
        // –ê–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ –±—É—Ñ–µ—Ä–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if let channelData = buffer.floatChannelData?[0] {
            let frameCount = Int(buffer.frameLength)
            let samplesToPrint = min(5, frameCount)
            
            var samplesInfo = "–ü–µ—Ä–≤—ã–µ \(samplesToPrint) —Å—ç–º–ø–ª–æ–≤: "
            for i in 0..<samplesToPrint {
                samplesInfo += String(format: "%.4f ", channelData[i])
            }
            print("üéµ \(samplesInfo)")
            
            // –ê–Ω–∞–ª–∏–∑ –∞–º–ø–ª–∏—Ç—É–¥—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ª–∏—á–∏—è —Ä–µ—á–∏
            let maxAmplitude = (0..<frameCount).map { abs(channelData[$0]) }.max() ?? 0
            print("üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞: \(maxAmplitude)")
            
            if maxAmplitude < 0.01 {
                print("‚ö†Ô∏è –ù–∏–∑–∫–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞ - –≤–æ–∑–º–æ–∂–Ω–æ —Ç–∏—à–∏–Ω–∞ –∏–ª–∏ —à—É–º")
            }
        }
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ 16kHz PCM –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é AVFoundation
        print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –∞—É–¥–∏–æ...")
        
        if let convertedFrames = convertBufferTo16kHzPCM(buffer) {
            print("‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: \(convertedFrames.count) —Ñ—Ä–µ–π–º–æ–≤")
            
            // –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if !convertedFrames.isEmpty {
                let samplesToPrint = min(5, convertedFrames.count)
                var samplesInfo = "–ü–µ—Ä–≤—ã–µ \(samplesToPrint) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤: "
                for i in 0..<samplesToPrint {
                    samplesInfo += String(format: "%.4f ", convertedFrames[i])
                }
                print("üéµ \(samplesInfo)")
                
                let maxAmplitude = convertedFrames.map { abs($0) }.max() ?? 0
                print("üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞ –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: \(maxAmplitude)")
            }
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ—Ä–µ–π–º—ã —á–µ—Ä–µ–∑ delegate
            DispatchQueue.main.async {
                print("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º \(convertedFrames.count) —Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
                self.delegate?.audioRecordingManager(self, didProduceAudioFrames: convertedFrames)
            }
        } else {
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ")
        }
    }
    
    /// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±—É—Ñ–µ—Ä–∞ –∞—É–¥–∏–æ –≤ PCM 16kHz
    /// Convert audio buffer to 16kHz PCM
    private func convertBufferTo16kHzPCM(_ buffer: AVAudioPCMBuffer) -> [Float]? {
        guard let channelData = buffer.floatChannelData?[0] else { return nil }
        
        let frameCount = Int(buffer.frameLength)
        let inputFormat = buffer.format
        let targetSampleRate: Double = 16000
        
        print("üîä Converting audio from \(inputFormat.sampleRate)Hz to \(targetSampleRate)Hz")
        
        // –ï—Å–ª–∏ —É–∂–µ 16kHz, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if inputFormat.sampleRate == targetSampleRate {
            print("üîä Audio already at target sample rate, no conversion needed")
            return Array(UnsafeBufferPointer(start: channelData, count: frameCount))
        }
        
        // –†–µ—Å—ç–º–ø–ª–∏–Ω–≥ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è sample rate
        let ratio = targetSampleRate / inputFormat.sampleRate
        let outputFrameCount = Int(Double(frameCount) * ratio)
        
        print("üîä Resampling ratio: \(ratio), output frame count: \(outputFrameCount)")
        
        var outputFrames: [Float] = []
        outputFrames.reserveCapacity(outputFrameCount)
        
        // –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥–∞
        for i in 0..<outputFrameCount {
            let sourceIndex = Double(i) / ratio
            let lowerIndex = Int(sourceIndex)
            let upperIndex = min(lowerIndex + 1, frameCount - 1)
            let fraction = sourceIndex - Double(lowerIndex)
            
            if lowerIndex >= frameCount || upperIndex >= frameCount {
                continue
            }
            
            let lowerValue = channelData[lowerIndex]
            let upperValue = channelData[upperIndex]
            let interpolatedValue = lowerValue + Float(fraction) * (upperValue - lowerValue)
            
            outputFrames.append(interpolatedValue)
        }
        
        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        let maxAmplitude = outputFrames.map { abs($0) }.max() ?? 1.0
        if maxAmplitude > 0.01 {
            let normalizedFrames = outputFrames.map { $0 / maxAmplitude * 0.9 }
            print("üîä Audio normalized with max amplitude: \(maxAmplitude)")
            return normalizedFrames
        } else {
            print("‚ö†Ô∏è Very low amplitude, amplifying signal")
            let amplifiedFrames = outputFrames.map { $0 * 50.0 }
            return amplifiedFrames
        }
    }
    
}

// MARK: - Audio Recording Errors
enum AudioRecordingError: Error, LocalizedError {
    case microphonePermissionDenied
    case audioSessionConfigurationFailed
    case audioEngineSetupFailed
    case notRecording
    case recordingFailed
    
    var errorDescription: String? {
        switch self {
        case .microphonePermissionDenied:
            return "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"
        case .audioSessionConfigurationFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏"
        case .audioEngineSetupFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ –¥–≤–∏–∂–∫–∞"
        case .notRecording:
            return "–ó–∞–ø–∏—Å—å –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞"
        case .recordingFailed:
            return "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ"
        }
    }
}

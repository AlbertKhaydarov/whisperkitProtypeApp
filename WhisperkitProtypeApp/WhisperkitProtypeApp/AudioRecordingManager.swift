//
//  AudioRecordingManager.swift
//  WhisperkitProtypeApp
//
//  Created by AI Assistant on 21.10.2025.
//

import Foundation
import AVFoundation
import WhisperKit


// MARK: - AudioRecordingManager Delegate
protocol AudioRecordingManagerDelegate: AnyObject {
    func audioRecordingManager(_ manager: AudioRecordingManager, didStartRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didStopRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didProduceAudioFrames frames: [Float])
    func audioRecordingManager(_ manager: AudioRecordingManager, didFailWith error: Error)
    func audioRecordingManager(_ manager: AudioRecordingManager, didTranscribeFile filePath: String)
}

/// –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç 16kHz PCM
/// Manager for audio recording and conversion to 16kHz PCM format
class AudioRecordingManager: NSObject {
    
    // MARK: - Properties
    private let audioEngine: AVAudioEngine
    private let audioConverter: AVAudioConverter?
    private var isRecording = false
    
    // MARK: - Debug Properties
    private var debugAudioFile: AVAudioFile?
    private var debugAudioBuffer: [Float] = []
    
    // MARK: - Delegate
    weak var delegate: AudioRecordingManagerDelegate?
    
    // MARK: - Initialization
    override init() {
        self.audioEngine = AVAudioEngine()
        self.audioConverter = nil
        super.init()
        // –ù–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –≤ init, –¥–µ–ª–∞–µ–º —ç—Ç–æ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∑–∞–ø–∏—Å–∏
    }
    
    // MARK: - Public Methods
    
    /// –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    /// Request microphone permission
    func requestMicrophonePermission() async -> Bool {
        #if os(iOS)
        return await withCheckedContinuation { continuation in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
        #else
        // –ù–∞ macOS —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        return true
        #endif
    }
    
    /// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏
    /// Configure audio session
    func configureAudioSession() async throws {
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        
        try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
        try audioSession.setActive(true)
        
        #else
        // –ù–∞ macOS –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        #endif
    }
    
    /// –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
    /// Start recording
    func startRecording() async throws {
        guard !isRecording else {
            print("‚ö†Ô∏è Already recording")
            return
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
        guard await requestMicrophonePermission() else {
            throw AudioRecordingError.microphonePermissionDenied
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—é
        try await configureAudioSession()
        
        // –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
        if audioEngine.isRunning {
            audioEngine.stop()
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫ –ë–ï–ó tap
        setupAudioEngineWithoutTap()
        
        // –ó–∞–ø—É—Å–∫–∞–µ–º –¥–≤–∏–∂–æ–∫ —Å–Ω–∞—á–∞–ª–∞
        do {
            try audioEngine.start()
        } catch {
            print("‚ùå Failed to start audio engine: \(error)")
            throw AudioRecordingError.audioEngineSetupFailed
        }
        
        // –¢–µ–ø–µ—Ä—å —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –¥–≤–∏–∂–∫–∞
        setupAudioTap()
        
        // –°–æ–∑–¥–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª
        do {
            try await setupDebugAudioFile()
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: \(error)")
        }
        
        isRecording = true
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStartRecording: true)
        }
    }
    
    /// –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
    /// Stop recording
    func stopRecording() async throws {
        guard isRecording else {
            print("‚ö†Ô∏è Not recording")
            return
        }
        
        // –£–¥–∞–ª—è–µ–º tap —Å –≤—Ö–æ–¥–Ω–æ–≥–æ —É–∑–ª–∞
        let inputNode = audioEngine.inputNode
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫
        audioEngine.stop()
        
        // –ó–∞–≤–µ—Ä—à–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
        await finishDebugAudioFile()
        
        isRecording = false
        
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStopRecording: true)
        }
    }
    
    /// –ü–∞—É–∑–∞ –∑–∞–ø–∏—Å–∏
    /// Pause recording
    func pauseRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        audioEngine.pause()
    }
    
    /// –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏
    /// Resume recording
    func resumeRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        try audioEngine.start()
    }
    
    /// –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–∏—Å–∏
    /// Check recording status
    func isCurrentlyRecording() -> Bool {
        return isRecording
    }
    
    // MARK: - Private Methods
    
    private func setupAudioEngineWithoutTap() {
        // –ü—Ä–æ—Å—Ç–æ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –±–µ–∑ tap
        let inputNode = audioEngine.inputNode
        
        // –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ tap
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
    }
    
    private func setupAudioTap() {
        let inputNode = audioEngine.inputNode
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è tap
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, time in
            self?.processAudioBuffer(buffer, time: time)
        }
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, time: AVAudioTime) {
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if let convertedFrames = convertBufferTo16kHzPCM(buffer) {
            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª
            writeDebugAudioToFile(convertedFrames)
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ—Ä–µ–π–º—ã —á–µ—Ä–µ–∑ delegate
            DispatchQueue.main.async {
                self.delegate?.audioRecordingManager(self, didProduceAudioFrames: convertedFrames)
            }
        }
    }
    
    /// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±—É—Ñ–µ—Ä–∞ –∞—É–¥–∏–æ –≤ PCM 16kHz
    /// Convert audio buffer to 16kHz PCM
    private func convertBufferTo16kHzPCM(_ buffer: AVAudioPCMBuffer) -> [Float]? {
        guard let channelData = buffer.floatChannelData?[0] else { return nil }
        
        let frameCount = Int(buffer.frameLength)
        let inputFormat = buffer.format
        let targetSampleRate: Double = 16000
        
        
        // –ï—Å–ª–∏ —É–∂–µ 16kHz, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if inputFormat.sampleRate == targetSampleRate {
            return Array(UnsafeBufferPointer(start: channelData, count: frameCount))
        }
        
        // –†–µ—Å—ç–º–ø–ª–∏–Ω–≥ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è sample rate
        let ratio = targetSampleRate / inputFormat.sampleRate
        let outputFrameCount = Int(Double(frameCount) * ratio)
        
        
        var outputFrames: [Float] = []
        outputFrames.reserveCapacity(outputFrameCount)
        
        // –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥–∞
        for i in 0..<outputFrameCount {
            let sourceIndex = Double(i) / ratio
            let lowerIndex = Int(sourceIndex)
            let upperIndex = min(lowerIndex + 1, frameCount - 1)
            let fraction = sourceIndex - Double(lowerIndex)
            
            if lowerIndex >= frameCount || upperIndex >= frameCount {
                continue
            }
            
            let lowerValue = channelData[lowerIndex]
            let upperValue = channelData[upperIndex]
            let interpolatedValue = lowerValue + Float(fraction) * (upperValue - lowerValue)
            
            outputFrames.append(interpolatedValue)
        }
        
        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        let maxAmplitude = outputFrames.map { abs($0) }.max() ?? 1.0
        if maxAmplitude > 0.01 {
            let normalizedFrames = outputFrames.map { $0 / maxAmplitude * 0.9 }
            return normalizedFrames
        } else {
            let amplifiedFrames = outputFrames.map { $0 * 50.0 }
            return amplifiedFrames
        }
    }
    
    // MARK: - Debug Audio File Methods
    
    /// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
    /// Setup debug audio file for recording
    private func setupDebugAudioFile() async throws {
        // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let debugDirectory = documentsPath.appendingPathComponent("DebugAudio")
        
        // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        try FileManager.default.createDirectory(at: debugDirectory, withIntermediateDirectories: true, attributes: nil)
        
        // –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        let timestamp = Int(Date().timeIntervalSince1970)
        let fileName = "debug_audio_\(timestamp).wav"
        let fileURL = debugDirectory.appendingPathComponent(fileName)
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∑–∞–ø–∏—Å–∏ (16kHz, 16-bit, mono)
        let audioFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: 16000,
            channels: 1,
            interleaved: false
        )!
        
        // –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
        debugAudioFile = try AVAudioFile(forWriting: fileURL, settings: audioFormat.settings)
        debugAudioBuffer.removeAll()
        
        print("üéµ –û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: \(fileURL.lastPathComponent)")
    }
    
    /// –ó–∞–ø–∏—Å—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª
    /// Write debug audio data to file
    private func writeDebugAudioToFile(_ frames: [Float]) {
        guard let audioFile = debugAudioFile else { 
            return 
        }
        
        // –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ—Ä–µ–π–º–∞—Ö
        if frames.count > 0 {
            let maxAmplitude = frames.map { abs($0) }.max() ?? 0
            print("üéµ –ó–∞–ø–∏—Å—ã–≤–∞–µ–º \(frames.count) —Ñ—Ä–µ–π–º–æ–≤, –º–∞–∫—Å. –∞–º–ø–ª–∏—Ç—É–¥–∞: \(maxAmplitude)")
        }
        
        // –î–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–µ–π–º—ã –≤ –±—É—Ñ–µ—Ä
        debugAudioBuffer.append(contentsOf: frames)
        
        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª –∫–∞–∂–¥—ã–µ 1000 —Ñ—Ä–µ–π–º–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ 62.5ms –ø—Ä–∏ 16kHz)
        if debugAudioBuffer.count >= 1000 {
            let framesToWrite = Array(debugAudioBuffer.prefix(1000))
            debugAudioBuffer.removeFirst(1000)
            
            // –°–æ–∑–¥–∞–µ–º PCM –±—É—Ñ–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏
            let buffer = AVAudioPCMBuffer(pcmFormat: audioFile.processingFormat, frameCapacity: AVAudioFrameCount(framesToWrite.count))!
            buffer.frameLength = AVAudioFrameCount(framesToWrite.count)
            
            // –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä
            if let channelData = buffer.floatChannelData?[0] {
                for (index, sample) in framesToWrite.enumerated() {
                    channelData[index] = sample
                }
            }
            
            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
            do {
                try audioFile.write(from: buffer)
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π —Ñ–∞–π–ª: \(error)")
            }
        }
    }
    
    /// –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    /// Finish debug audio file recording
    private func finishDebugAudioFile() async {
        guard let audioFile = debugAudioFile else { return }
        
        print("üîÑ –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–ø–∏—Å—å –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞. –û—Å—Ç–∞–ª–æ—Å—å —Ñ—Ä–µ–π–º–æ–≤: \(debugAudioBuffer.count)")
        
        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ
        if !debugAudioBuffer.isEmpty {
            let buffer = AVAudioPCMBuffer(pcmFormat: audioFile.processingFormat, frameCapacity: AVAudioFrameCount(debugAudioBuffer.count))!
            buffer.frameLength = AVAudioFrameCount(debugAudioBuffer.count)
            
            if let channelData = buffer.floatChannelData?[0] {
                for (index, sample) in debugAudioBuffer.enumerated() {
                    channelData[index] = sample
                }
            }
            
            do {
                try audioFile.write(from: buffer)
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö: \(error)")
            }
        }
        
        // –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª
        let fileURL = audioFile.url
        debugAudioFile = nil
        debugAudioBuffer.removeAll()
        
        print("‚úÖ –û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: \(fileURL.lastPathComponent)")
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ WhisperKit
        await transcribeAudioFile(fileURL)
    }
    
    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ WhisperKit
    /// Transcribe audio file using WhisperKit
    private func transcribeAudioFile(_ fileURL: URL) async {
        print("üéµ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∞–π–ª–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é: \(fileURL.lastPathComponent)")
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        do {
            let fileAttributes = try FileManager.default.attributesOfItem(atPath: fileURL.path)
            if let fileSize = fileAttributes[.size] as? NSNumber {
                print("üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: \(fileSize.intValue) –±–∞–π—Ç")
                if fileSize.intValue < 1000 {
                    print("‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π! –í–æ–∑–º–æ–∂–Ω–æ, –∞—É–¥–∏–æ –Ω–µ –∑–∞–ø–∏—Å–∞–ª–æ—Å—å.")
                }
            }
        } catch {
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: \(error)")
        }
        
        do {
            // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ WhisperKit, —á—Ç–æ –∏ –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            // –ü–µ—Ä–µ–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —á–µ—Ä–µ–∑ delegate –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            print("üîÑ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —á–µ—Ä–µ–∑ RecognitionPresenter...")
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª —á–µ—Ä–µ–∑ delegate –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            await MainActor.run {
                self.delegate?.audioRecordingManager(self, didTranscribeFile: fileURL.path)
            }
            return
            
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é: \(error.localizedDescription)")
        }
    }
    
}

// MARK: - Audio Recording Errors
enum AudioRecordingError: Error, LocalizedError {
    case microphonePermissionDenied
    case audioSessionConfigurationFailed
    case audioEngineSetupFailed
    case notRecording
    case recordingFailed
    
    var errorDescription: String? {
        switch self {
        case .microphonePermissionDenied:
            return "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"
        case .audioSessionConfigurationFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏"
        case .audioEngineSetupFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ –¥–≤–∏–∂–∫–∞"
        case .notRecording:
            return "–ó–∞–ø–∏—Å—å –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞"
        case .recordingFailed:
            return "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ"
        }
    }
}

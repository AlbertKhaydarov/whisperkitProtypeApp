//
//  AudioRecordingManager.swift
//  WhisperkitProtypeApp
//
//  Created by AI Assistant on 21.10.2025.
//

import Foundation
import AVFoundation
import SwiftWhisper


// MARK: - AudioRecordingManager Delegate
protocol AudioRecordingManagerDelegate: AnyObject {
    func audioRecordingManager(_ manager: AudioRecordingManager, didStartRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didStopRecording: Bool)
    func audioRecordingManager(_ manager: AudioRecordingManager, didProduceAudioFrames frames: [Float])
    func audioRecordingManager(_ manager: AudioRecordingManager, didFailWith error: Error)
}

/// –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç 16kHz PCM
/// Manager for audio recording and conversion to 16kHz PCM format
class AudioRecordingManager: NSObject {
    
    // MARK: - Properties
    private let audioEngine: AVAudioEngine
    private let audioConverter: AVAudioConverter?
    private var isRecording = false
    
    // MARK: - Delegate
    weak var delegate: AudioRecordingManagerDelegate?
    
    // MARK: - Initialization
    override init() {
        self.audioEngine = AVAudioEngine()
        self.audioConverter = nil
        super.init()
        // –ù–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –≤ init, –¥–µ–ª–∞–µ–º —ç—Ç–æ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∑–∞–ø–∏—Å–∏
    }
    
    // MARK: - Public Methods
    
    /// –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    /// Request microphone permission
    func requestMicrophonePermission() async -> Bool {
        #if os(iOS)
        return await withCheckedContinuation { continuation in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
        #else
        // –ù–∞ macOS —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        return true
        #endif
    }
    
    /// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏
    /// Configure audio session
    func configureAudioSession() async throws {
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        
        try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
        try audioSession.setActive(true)
        
        print("üé§ Audio session configured successfully")
        #else
        // –ù–∞ macOS –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        print("üé§ Audio session configured for macOS")
        #endif
    }
    
    /// –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏
    /// Start recording
    func startRecording() async throws {
        guard !isRecording else {
            print("‚ö†Ô∏è Already recording")
            return
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
        guard await requestMicrophonePermission() else {
            throw AudioRecordingError.microphonePermissionDenied
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—é
        try await configureAudioSession()
        
        // –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
        if audioEngine.isRunning {
            audioEngine.stop()
        }
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫ –ë–ï–ó tap
        setupAudioEngineWithoutTap()
        
        // –ó–∞–ø—É—Å–∫–∞–µ–º –¥–≤–∏–∂–æ–∫ —Å–Ω–∞—á–∞–ª–∞
        do {
            try audioEngine.start()
            print("üé§ Audio engine started")
        } catch {
            print("‚ùå Failed to start audio engine: \(error)")
            throw AudioRecordingError.audioEngineSetupFailed
        }
        
        // –¢–µ–ø–µ—Ä—å —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –¥–≤–∏–∂–∫–∞
        setupAudioTap()
        
        isRecording = true
        print("üé§ Recording started")
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStartRecording: true)
        }
    }
    
    /// –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
    /// Stop recording
    func stopRecording() async throws {
        guard isRecording else {
            print("‚ö†Ô∏è Not recording")
            return
        }
        
        // –£–¥–∞–ª—è–µ–º tap —Å –≤—Ö–æ–¥–Ω–æ–≥–æ —É–∑–ª–∞
        let inputNode = audioEngine.inputNode
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫
        audioEngine.stop()
        
        isRecording = false
        
        print("‚èπÔ∏è Recording stopped")
        
        await MainActor.run {
            delegate?.audioRecordingManager(self, didStopRecording: true)
        }
    }
    
    /// –ü–∞—É–∑–∞ –∑–∞–ø–∏—Å–∏
    /// Pause recording
    func pauseRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        audioEngine.pause()
        print("‚è∏Ô∏è Recording paused")
    }
    
    /// –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏
    /// Resume recording
    func resumeRecording() async throws {
        guard isRecording else {
            throw AudioRecordingError.notRecording
        }
        
        try audioEngine.start()
        print("‚ñ∂Ô∏è Recording resumed")
    }
    
    /// –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–∏—Å–∏
    /// Check recording status
    func isCurrentlyRecording() -> Bool {
        return isRecording
    }
    
    // MARK: - Private Methods
    
    private func setupAudioEngineWithoutTap() {
        // –ü—Ä–æ—Å—Ç–æ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –±–µ–∑ tap
        let inputNode = audioEngine.inputNode
        
        // –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ tap
        if inputNode.numberOfInputs > 0 {
            inputNode.removeTap(onBus: 0)
        }
        
        print("üé§ Audio engine prepared (without tap)")
    }
    
    private func setupAudioTap() {
        let inputNode = audioEngine.inputNode
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è tap
        let inputFormat = inputNode.outputFormat(forBus: 0)
        print("üé§ Input format: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount) channels")
        
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, time in
            self?.processAudioBuffer(buffer, time: time)
        }
        print("üé§ Audio tap installed successfully")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, time: AVAudioTime) {
        // –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ 16kHz PCM –∏—Å–ø–æ–ª—å–∑—É—è AudioKit –ø–æ–¥—Ö–æ–¥
        guard let convertedFrames = convertBufferTo16kHzPCM(buffer) else {
            print("‚ùå Failed to convert audio buffer")
            return
        }
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ—Ä–µ–π–º—ã —á–µ—Ä–µ–∑ delegate
        DispatchQueue.main.async { [weak self] in
            self?.delegate?.audioRecordingManager(self!, didProduceAudioFrames: convertedFrames)
        }
    }
    
    private func convertBufferTo16kHzPCM(_ buffer: AVAudioPCMBuffer) -> [Float]? {
        guard let channelData = buffer.floatChannelData?[0] else { return nil }
        
        let frameCount = Int(buffer.frameLength)
        let inputFormat = buffer.format
        let targetSampleRate: Double = 16000
        
        // –ï—Å–ª–∏ —É–∂–µ 16kHz, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if inputFormat.sampleRate == targetSampleRate {
            return Array(UnsafeBufferPointer(start: channelData, count: frameCount))
        }
        
        // –ü—Ä–æ—Å—Ç–∞—è —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è sample rate
        let ratio = targetSampleRate / inputFormat.sampleRate
        let outputFrameCount = Int(Double(frameCount) * ratio)
        
        var outputFrames: [Float] = []
        outputFrames.reserveCapacity(outputFrameCount)
        
        // –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥–∞
        for i in 0..<outputFrameCount {
            let sourceIndex = Double(i) / ratio
            let lowerIndex = Int(sourceIndex)
            let upperIndex = min(lowerIndex + 1, frameCount - 1)
            let fraction = sourceIndex - Double(lowerIndex)
            
            let lowerValue = channelData[lowerIndex]
            let upperValue = channelData[upperIndex]
            let interpolatedValue = lowerValue + Float(fraction) * (upperValue - lowerValue)
            
            outputFrames.append(interpolatedValue)
        }
        
        return outputFrames
    }
}

// MARK: - Audio Recording Errors
enum AudioRecordingError: Error, LocalizedError {
    case microphonePermissionDenied
    case audioSessionConfigurationFailed
    case audioEngineSetupFailed
    case notRecording
    case recordingFailed
    
    var errorDescription: String? {
        switch self {
        case .microphonePermissionDenied:
            return "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"
        case .audioSessionConfigurationFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏"
        case .audioEngineSetupFailed:
            return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ –¥–≤–∏–∂–∫–∞"
        case .notRecording:
            return "–ó–∞–ø–∏—Å—å –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞"
        case .recordingFailed:
            return "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ"
        }
    }
}

//
//  AudioRecordingManager.swift
//  WhisperkitProtypeApp
//
//  Created by AlbertKh on 19.10.2025.
//

import Foundation
import AVFoundation
import WhisperKit

/// –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –∏ –ø–µ—Ä–µ–¥–∞—á–∏ –≤ WhisperKit (Thread-Safe –≤–µ—Ä—Å–∏—è)
/// Manager for audio recording and passing to WhisperKit (Thread-Safe version)
actor AudioRecordingManager {
    private var streamTranscriber: AudioStreamTranscriber?
    private weak var delegate: TranscriptionDelegate?
    
    // –£–¥–∞–ª—è–µ–º NotificationCenter observers - –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ async/await
    // Remove NotificationCenter observers - replace with async/await
    private var isRecording = false
    private var audioSessionTask: Task<Void, Never>?

    // –ó–∞—â–∏—Ç–∞ –æ—Ç concurrent –¥–æ—Å—Ç—É–ø–∞ –∫ audio session
    // Protection against concurrent access to audio session
    private var isConfiguringAudioSession = false
    

    // –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è audio route –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    // Track audio route state to log only changes
    private var lastAudioRoute: String?
    private var lastAudioSessionState: Bool = true

    // –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ regex –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    // Cached regex for optimization
    private static let timestampRegex = try? NSRegularExpression(
        pattern: "<\\|\\d+\\.\\d+\\|>|\\[\\s*\\]|\\[\\s*end\\s*\\]|\\|\\s*",
        options: []
    )

    private static let serviceTokensRegex = try? NSRegularExpression(
        pattern: "<\\|startoftranscript\\|>|<\\|endoftext\\|>|Waiting for speech\\.\\.\\.?|\\[end\\]",
        options: []
    )

    // MARK: - Audio Configuration Constants
    // –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ
    // Audio configuration constants

    /// –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
    /// Number of confirmed segments required for longer phrases
    private static let requiredSegmentsForConfirmation = 3

    /// –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ —Ñ—Ä–∞–∑—ã (0.0 - 1.0)
    /// Silence threshold for detecting end of phrase (0.0 - 1.0)
    private static let silenceThreshold: Float = 0.3

    /// –û–∫–Ω–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –∞—É–¥–∏–æ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É—Ñ–µ—Ä–æ–≤)
    /// Window for audio compression check (number of buffers)
    private static let compressionCheckWindow = 20

    /// –†–∞–∑–º–µ—Ä IO –±—É—Ñ–µ—Ä–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (100ms –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ latency/quality)
    /// IO buffer size in seconds (100ms for latency/quality balance)
    private static let preferredIOBufferDuration: TimeInterval = 0.1

    /// –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è WhisperKit (16kHz —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é)
    /// Sample rate for WhisperKit (16kHz required by model)
    private static let preferredSampleRate: Double = 16000

    /// –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ audio session –≤ –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥–∞—Ö (100ms)
    /// Audio session monitoring interval in nanoseconds (100ms)
    private static let monitoringInterval: UInt64 = 100_000_000

    init() {
        // –ë–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã NotificationCenter observers
        // No longer need NotificationCenter observers
    }

    deinit {
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø—Ä–∏ –¥–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        // Stop all tasks on deinitialization
        audioSessionTask?.cancel()

        // –ü—ã—Ç–∞–µ–º—Å—è –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å audio session —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        // Try to deactivate audio session synchronously
        try? AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)

        print("üóëÔ∏è AudioRecordingManager –¥–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    }

    /// –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session —Å –ø–æ–º–æ—â—å—é async/await
    /// Start audio session monitoring using async/await
    private func startAudioSessionMonitoring() {
        audioSessionTask = Task { [weak self] in
            await self?.monitorAudioSession()
        }
    }
    
    /// –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session
    /// Stop audio session monitoring
    private func stopAudioSessionMonitoring() {
        audioSessionTask?.cancel()
        audioSessionTask = nil
    }
    
    /// –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session —Å –ø–æ–º–æ—â—å—é async/await
    /// Monitor audio session using async/await
    private func monitorAudioSession() async {
        while !Task.isCancelled {
            do {
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ audio session –∫–∞–∂–¥—ã–µ 100ms
                // Check audio session state every 100ms
                try await Task.sleep(nanoseconds: Self.monitoringInterval)
                
                // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Å–æ—Å—Ç–æ—è–Ω–∏—è
                // Use centralized state checking
                await checkAudioSessionState()
                
            } catch {
                // Task –±—ã–ª –æ—Ç–º–µ–Ω–µ–Ω
                // Task was cancelled
                break
            }
        }
    }

    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
    /// Check microphone permission
    private func checkMicrophonePermission() async -> Bool {
        let status = AVAudioSession.sharedInstance().recordPermission

        switch status {
        case .granted:
            print("‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ–ª—É—á–µ–Ω–æ")
            return true

        case .denied:
            print("‚ùå –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ")
            return false

        case .undetermined:
            print("‚ùì –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
            return await withCheckedContinuation { continuation in
                AVAudioSession.sharedInstance().requestRecordPermission { granted in
                    print(granted ? "‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ" : "‚ùå –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ")
                    continuation.resume(returning: granted)
                }
            }

        @unknown default:
            return false
        }
    }

    /// –ù–∞—Å—Ç—Ä–æ–∏—Ç—å audio session –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ä–µ—á–∏
    /// Setup audio session for speech recording
    nonisolated private func setupAudioSession() throws {
        let audioSession = AVAudioSession.sharedInstance()

        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ä–µ—á–∏
        // Setup category for speech recording
        try audioSession.setCategory(
            .record,
            mode: .voiceChat, // –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –≥–æ–ª–æ—Å–∞, –≤–∫–ª—é—á–∞–µ—Ç —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
            options: [
                .allowBluetooth,
                .allowBluetoothA2DP
            ]
        )

        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        // Setup preferred parameters
        try audioSession.setPreferredSampleRate(Self.preferredSampleRate)
        try audioSession.setPreferredIOBufferDuration(Self.preferredIOBufferDuration)

        // –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é
        // Activate session
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        print("üé§ Audio session –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏")
    }

    /// –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å
    /// Start recording
    func startRecording(
        whisperKit: WhisperKit,
        decodingOptions: DecodingOptions,
        delegate: TranscriptionDelegate
    ) async throws {
        print("üé§ AudioRecordingManager.startRecording –≤—ã–∑–≤–∞–Ω")

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
        // Check microphone permission
        let permission = await checkMicrophonePermission()
        guard permission else {
            let error = NSError(
                domain: "AudioRecordingManager",
                code: -1,
                userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"]
            )
            print("‚ùå –ù–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
            await notifyDelegateError(error)
            throw error
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞ –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—å
        // Check if recording is already running
        if streamTranscriber != nil {
            print("‚ö†Ô∏è –ó–∞–ø–∏—Å—å —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é...")
            await stopRecording()
            print("‚ö†Ô∏è –ü—Ä–µ–¥—ã–¥—É—â–∞—è –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ç–æ–º–∞—Ä–Ω–æ
        // Check and set configuration flag atomically
        guard !isConfiguringAudioSession else {
            let error = NSError(
                domain: "AudioRecordingManager",
                code: -2,
                userInfo: [NSLocalizedDescriptionKey: "Audio session is already being configured"]
            )
            print("‚ùå Audio session —É–∂–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è")
            await notifyDelegateError(error)
            throw error
        }
        
        isConfiguringAudioSession = true
        defer { isConfiguringAudioSession = false }

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–ª–µ–≥–∞—Ç–∞
        // Store delegate
        self.delegate = delegate
        print("üé§ –î–µ–ª–µ–≥–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

        // –ù–∞—Å—Ç—Ä–æ–∏—Ç—å audio session
        // Setup audio session
        print("üé§ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º audio session...")

        do {
            try setupAudioSession()
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ audio session: \(error)")
            await notifyDelegateError(error)
            throw error
        }
        
        // –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session
        // Start audio session monitoring
        startAudioSessionMonitoring()
        print("üé§ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session –∑–∞–ø—É—â–µ–Ω")

        // –°–æ–∑–¥–∞—Ç—å AudioStreamTranscriber —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        // Create AudioStreamTranscriber with correct parameters
        print("üé§ –°–æ–∑–¥–∞–µ–º AudioStreamTranscriber...")
        self.streamTranscriber = AudioStreamTranscriber(
            audioEncoder: whisperKit.audioEncoder,
            featureExtractor: whisperKit.featureExtractor,
            segmentSeeker: whisperKit.segmentSeeker,
            textDecoder: whisperKit.textDecoder,
            tokenizer: whisperKit.tokenizer!,
            audioProcessor: whisperKit.audioProcessor,
            decodingOptions: decodingOptions,
            requiredSegmentsForConfirmation: Self.requiredSegmentsForConfirmation,
            silenceThreshold: Self.silenceThreshold,
            compressionCheckWindow: Self.compressionCheckWindow,
            useVAD: true,
            stateChangeCallback: { [weak self] oldState, newState in
                Task { [weak self] in
                    await self?.handleStateChangeAsync(oldState, newState)
                }
            }
        )

        // –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        // Start streaming transcription
        print("üé§ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é...")
        try await streamTranscriber?.startStreamTranscription()
        print("üé§ –ü–æ—Ç–æ–∫–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–ø–∏—Å–∏
        // Set recording flag
        isRecording = true

        // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –Ω–∞—á–∞–ª–µ –∑–∞–ø–∏—Å–∏
        // Notify about recording start
        await notifyDelegateProgress(0.0)
    }

    /// –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
    /// Stop recording
    func stopRecording() async {
        print("üõë AudioRecordingManager.stopRecording –≤—ã–∑–≤–∞–Ω")

        // 1. –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        // Reset state flags
        isConfiguringAudioSession = false
        isRecording = false

        // 2. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        // Stop monitoring
        stopAudioSessionMonitoring()
        print("üõë –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ audio session –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        // 3. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        // Stop transcription
        await streamTranscriber?.stopStreamTranscription()
        print("üõë –ü–æ—Ç–æ–∫–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

        // 4. –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º audio session
        // Deactivate audio session
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
            print("üõë Audio session –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏ audio session: \(error)")
            await notifyDelegateError(error)
        }

        // 5. –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫–∏
        // Clear references
        streamTranscriber = nil

        // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏
        // Notify about recording completion
        await notifyDelegateProgress(1.0)

        delegate = nil
        print("üõë –†–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã")
    }

    /// –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (thread-safe –≤–µ—Ä—Å–∏—è)
    /// Handle transcription state changes (thread-safe version)
    private func handleStateChangeAsync(_ oldState: AudioStreamTranscriber.State, _ newState: AudioStreamTranscriber.State) async {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
        // Check if state actually changed
        let stateChanged = oldState.isRecording != newState.isRecording
        let textChanged = oldState.currentText != newState.currentText
        let confirmedChanged = oldState.confirmedSegments.count != newState.confirmedSegments.count
        let unconfirmedChanged = oldState.unconfirmedSegments.count != newState.unconfirmedSegments.count

        // –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
        // Log only on actual changes
        if stateChanged || textChanged || confirmedChanged || unconfirmedChanged {
            print("üé§ –°–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å: \(oldState.isRecording) -> \(newState.isRecording)")
            print("üé§ –¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç: '\(newState.currentText)'")
            print("üé§ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã: \(newState.confirmedSegments.count)")
            print("üé§ –ù–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã: \(newState.unconfirmedSegments.count)")
        }

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        // Send intermediate results only when changed
        if !newState.currentText.isEmpty && textChanged {
            let filteredText = filterServiceTokens(newState.currentText)
            if !filteredText.isEmpty {
                print("üìù –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: '\(filteredText)'")
                await notifyDelegateIntermediateResult(filteredText)
            }
        }

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ù–û–í–´–ï –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        // Send only NEW confirmed segments
        if !newState.confirmedSegments.isEmpty && confirmedChanged {
            let newConfirmedCount = newState.confirmedSegments.count
            let oldConfirmedCount = oldState.confirmedSegments.count

            if newConfirmedCount > oldConfirmedCount {
                let newSegments = Array(newState.confirmedSegments.suffix(newConfirmedCount - oldConfirmedCount))
                for segment in newSegments {
                    let filteredText = filterServiceTokens(segment.text)
                    if !filteredText.isEmpty {
                        print("‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç: '\(filteredText)'")
                        await notifyDelegateFinalResult(filteredText)
                    }
                }
            }
        }
    }

    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ audio session (–∑–∞–º–µ–Ω—è–µ—Ç NotificationCenter)
    /// Check audio session state (replaces NotificationCenter)
    private func checkAudioSessionState() async {
        let audioSession = AVAudioSession.sharedInstance()

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –Ω–∞–ø—Ä—è–º—É—é
        // Check recording interruption directly
        if isRecording && streamTranscriber == nil {
            print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ (streamTranscriber == nil), –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º...")
            await stopRecording()
            return
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–µ—Ä–≤–∞–Ω–æ –ª–∏ –∞—É–¥–∏–æ –¥—Ä—É–≥–∏–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º
        // Check if audio is interrupted by another app
        if audioSession.isOtherAudioPlaying && isRecording {
            print("‚ö†Ô∏è –î—Ä—É–≥–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –∞—É–¥–∏–æ, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...")
            await stopRecording()
            return
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –º–∞—Ä—à—Ä—É—Ç–∞ - –ª–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        // Check audio route availability - log only changes
        let currentRoute = audioSession.currentRoute
        let currentRouteDescription = currentRoute.outputs.first?.portName ?? "Unknown"
        let hasOutput = !currentRoute.outputs.isEmpty

        // –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        // Log only on state change
        if hasOutput != lastAudioSessionState || currentRouteDescription != lastAudioRoute {
            if hasOutput {
                print("‚úÖ –ê—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ: \(currentRouteDescription)")
            } else {
                print("‚ö†Ô∏è –ê—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
                if isRecording {
                    print("‚ö†Ô∏è –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏–∑-–∑–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")
                    await stopRecording()
                }
            }
            lastAudioSessionState = hasOutput
            lastAudioRoute = currentRouteDescription
        } else if !hasOutput && isRecording {
            // –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —É–∂–µ –±—ã–ª–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ, –Ω–æ –∑–∞–ø–∏—Å—å –≤—Å–µ –µ—â–µ –∏–¥–µ—Ç - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
            // Device was already disconnected, but recording is still active - stop it
            await stopRecording()
        }
    }

    /// –£–≤–µ–¥–æ–º–∏—Ç—å –¥–µ–ª–µ–≥–∞—Ç–∞ –æ–± –æ—à–∏–±–∫–µ (async/await –≤–µ—Ä—Å–∏—è)
    /// Notify delegate about error (async/await version)
    private func notifyDelegateError(_ error: Error) async {
        await MainActor.run { [weak delegate] in
            delegate?.didEncounterError(error)
        }
    }
    
    /// –£–≤–µ–¥–æ–º–∏—Ç—å –¥–µ–ª–µ–≥–∞—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ (async/await –≤–µ—Ä—Å–∏—è)
    /// Notify delegate about progress (async/await version)
    private func notifyDelegateProgress(_ progress: Float) async {
        await MainActor.run { [weak delegate] in
            delegate?.didUpdateProgress(progress)
        }
    }
    
    /// –£–≤–µ–¥–æ–º–∏—Ç—å –¥–µ–ª–µ–≥–∞—Ç–∞ –æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ (async/await –≤–µ—Ä—Å–∏—è)
    /// Notify delegate about intermediate result (async/await version)
    private func notifyDelegateIntermediateResult(_ text: String) async {
        await MainActor.run { [weak delegate] in
            delegate?.didReceiveIntermediateResult(text)
        }
    }
    
    /// –£–≤–µ–¥–æ–º–∏—Ç—å –¥–µ–ª–µ–≥–∞—Ç–∞ –æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ (async/await –≤–µ—Ä—Å–∏—è)
    /// Notify delegate about final result (async/await version)
    private func notifyDelegateFinalResult(_ text: String) async {
        await MainActor.run { [weak delegate] in
            delegate?.didReceiveFinalResult(text)
        }
    }

    /// –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã WhisperKit (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    /// Filter WhisperKit service tokens (optimized version)
    private func filterServiceTokens(_ text: String) -> String {
        guard !text.isEmpty, text.count > 5 else { return text }

        var filteredText = text

        // –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –æ–¥–Ω–æ–π regex –æ–ø–µ—Ä–∞—Ü–∏–µ–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        // Remove service tokens with one regex operation for efficiency
        if let serviceRegex = Self.serviceTokensRegex {
            let range = NSRange(filteredText.startIndex..<filteredText.endIndex, in: filteredText)
            filteredText = serviceRegex.stringByReplacingMatches(
                in: filteredText,
                options: [],
                range: range,
                withTemplate: ""
            )
        }

        // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –æ–¥–Ω–∏–º regex
        // Remove timestamps and service characters with one regex
        if let regex = Self.timestampRegex {
            let range = NSRange(filteredText.startIndex..<filteredText.endIndex, in: filteredText)
            filteredText = regex.stringByReplacingMatches(
                in: filteredText,
                options: [],
                range: range,
                withTemplate: ""
            )
        }

        // –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
        // Remove multiple spaces more efficiently
        filteredText = filteredText.replacingOccurrences(
            of: "\\s+",
            with: " ",
            options: .regularExpression
        ).trimmingCharacters(in: .whitespacesAndNewlines)

        return filteredText
    }
}

# üéôÔ∏è –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ WhisperKit –≤ iOS –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

> **WhisperKit** ‚Äî —ç—Ç–æ Swift-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (speech-to-text) –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö Apple —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ñ—Ñ–ª–∞–π–Ω —Ä–∞–±–æ—Ç–æ–π —á–µ—Ä–µ–∑ CoreML.

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#-1-—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
2. [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#-2-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
3. [–û—Å–Ω–æ–≤–Ω—ã–µ API —Ñ—É–Ω–∫—Ü–∏–∏](#-3-–æ—Å–Ω–æ–≤–Ω—ã–µ-api-—Ñ—É–Ω–∫—Ü–∏–∏)
4. [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è](#-4-–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)
5. [–†–∞–±–æ—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏](#-5-—Ä–∞–±–æ—Ç–∞-—Å-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏)
6. [–ü–æ–ª–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#-6-–ø–æ–ª–Ω—ã–µ-–ø—Ä–∏–º–µ—Ä—ã-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
7. [–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å](#-7-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è-–∏-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
8. [–†–∞–±–æ—Ç–∞ —Å —è–∑—ã–∫–∞–º–∏](#-8-—Ä–∞–±–æ—Ç–∞-—Å-—è–∑—ã–∫–∞–º–∏)
9. [–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫](#-9-–æ–±—Ä–∞–±–æ—Ç–∫–∞-–æ—à–∏–±–æ–∫)
10. [Best Practices](#-10-best-practices)

---

## üöÄ 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **iOS 16.0+** / macOS 13.0+ / watchOS 10.0+ / visionOS 1.0+
- **Xcode 15.0+**
- **Swift 5.9+**

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Swift Package Manager

#### –í–∞—Ä–∏–∞–Ω—Ç 1: –ß–µ—Ä–µ–∑ Xcode (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

1. –û—Ç–∫—Ä–æ–π—Ç–µ –≤–∞—à –ø—Ä–æ–µ–∫—Ç –≤ Xcode
2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ **File ‚Üí Add Package Dependencies...**
3. –í—Å—Ç–∞–≤—å—Ç–µ URL —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:
   ```
   https://github.com/argmaxinc/whisperkit
   ```
4. –í—ã–±–µ—Ä–∏—Ç–µ –≤–µ—Ä—Å–∏—é: **0.14.0** –∏–ª–∏ **Up to Next Major Version**
5. –ù–∞–∂–º–∏—Ç–µ **Add Package**

#### –í–∞—Ä–∏–∞–Ω—Ç 2: –ß–µ—Ä–µ–∑ Package.swift

–î–æ–±–∞–≤—å—Ç–µ –≤ —Ñ–∞–π–ª `Package.swift`:

```swift
dependencies: [
    .package(url: "https://github.com/argmaxinc/WhisperKit.git", from: "0.14.0")
],
targets: [
    .target(
        name: "YourApp",
        dependencies: ["WhisperKit"]
    )
]
```

### –ò–º–ø–æ—Ä—Ç –≤ –∫–æ–¥

```swift
import WhisperKit
```

---

## ‚ö° 2. –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä (3 —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞)

```swift
import WhisperKit

Task {
    let whisperKit = try await WhisperKit()
    let result = try await whisperKit.transcribe(audioPath: "path/to/audio.mp3")
    print(result?.text ?? "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
}
```

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º:

1. ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞—à–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
2. ‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è (–µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–∫–∞—á–∞–Ω–∞)
3. ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å
4. ‚úÖ –ê—É–¥–∏–æ —Ñ–∞–π–ª –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç—Å—è

---

## üîß 3. –û—Å–Ω–æ–≤–Ω—ã–µ API —Ñ—É–Ω–∫—Ü–∏–∏

### 3.1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperKit

#### –ë–∞–∑–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

```swift
let whisperKit = try await WhisperKit()
```

#### –° –≤—ã–±–æ—Ä–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏

```swift
let whisperKit = try await WhisperKit(
    WhisperKitConfig(model: "small-en")
)
```

#### –° –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π

```swift
let config = WhisperKitConfig(
    model: "small-en",
    verbose: true,              // –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
    download: true,             // –ê–≤—Ç–æ—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    prewarm: true,             // –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    load: true                 // –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å—Ä–∞–∑—É
)

let whisperKit = try await WhisperKit(config)
```

### 3.2. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –Ø–∑—ã–∫–∏ | –°–∫–æ—Ä–æ—Å—Ç—å | –¢–æ—á–Ω–æ—Å—Ç—å | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
|--------|--------|-------|----------|----------|---------------|
| `tiny-en` | ~30 MB | –ê–Ω–≥–ª–∏–π—Å–∫–∏–π | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Real-time, –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã |
| `base-en` | ~70 MB | –ê–Ω–≥–ª–∏–π—Å–∫–∏–π | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ |
| `small-en` | ~250 MB | –ê–Ω–≥–ª–∏–π—Å–∫–∏–π | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| `medium-en` | ~750 MB | –ê–Ω–≥–ª–∏–π—Å–∫–∏–π | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| `large-v3` | ~1.5 GB | 100+ —è–∑—ã–∫–æ–≤ | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| `distil-large-v3` | ~800 MB | 100+ —è–∑—ã–∫–æ–≤ | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | –î–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è |

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ú–æ–¥–µ–ª–∏ —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º `-en` —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–æ–º, –Ω–æ –±—ã—Å—Ç—Ä–µ–µ –∏ —Ç—Ä–µ–±—É—é—Ç –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏.

### 3.3. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–∞

#### –ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ

```swift
let result = try await whisperKit.transcribe(audioPath: "path/to/audio.mp3")
print(result?.text ?? "")
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:** `.wav`, `.mp3`, `.m4a`, `.flac`

#### –° –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

```swift
var options = DecodingOptions()
options.language = "ru"           // –†—É—Å—Å–∫–∏–π —è–∑—ã–∫
options.task = .transcribe        // –ò–ª–∏ .translate –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
options.temperature = 0.0         // –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

let result = try await whisperKit.transcribe(
    audioPath: audioPath,
    decodeOptions: options
)
print(result?.text ?? "")
```

### 3.4. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏

```swift
var options = DecodingOptions()
options.wordTimestamps = true     // –ú–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞

let result = try await whisperKit.transcribe(
    audioPath: audioPath,
    decodeOptions: options
)

// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –º–µ—Ç–∫–∞–º–∏
if let segments = result?.segments {
    for segment in segments {
        print("[\(segment.start)s - \(segment.end)s]: \(segment.text)")
        
        // –ú–µ—Ç–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤
        if options.wordTimestamps {
            for token in segment.tokens {
                print("  '\(token.text)' at \(token.timestamp)s")
            }
        }
    }
}
```

### 3.5. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –∫–æ–ª–±—ç–∫–∞–º–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤

```swift
let result = try await whisperKit.transcribe(
    audioArray: audioSamples,  // –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ audioPath –¥–ª—è —Ñ–∞–π–ª–∞
    decodeOptions: options,
    callback: { progress in
        // TranscriptionCallback - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        DispatchQueue.main.async {
            print("–¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç: \(progress.text)")
            print("–ü—Ä–æ–≥—Ä–µ—Å—Å: \(progress.timings)")
        }
        return nil  // –í–µ—Ä–Ω—É—Ç—å nil –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏–ª–∏ false –¥–ª—è –æ—Ç–º–µ–Ω—ã
    },
    segmentCallback: { segments in
        // SegmentDiscoveryCallback - –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ –º–µ—Ä–µ –∏—Ö —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        DispatchQueue.main.async {
            for segment in segments {
                print("–ù–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç [\(segment.start)s - \(segment.end)s]: \(segment.text)")
            }
        }
    }
)
```

### 3.6. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –º–∞—Å—Å–∏–≤–∞ –∞—É–¥–∏–æ-–¥–∞–Ω–Ω—ã—Ö

–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥–∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –∏–∑ –º–∞—Å—Å–∏–≤–∞:

```swift
// audioSamples - –º–∞—Å—Å–∏–≤ Float —Å —á–∞—Å—Ç–æ—Ç–æ–π 16000 Hz
let audioSamples: [Float] = // ... –ø–æ–ª—É—á–µ–Ω–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏–ª–∏ —Ñ–∞–π–ª–∞

var options = DecodingOptions()
options.language = "ru"

let result = try await whisperKit.transcribe(
    audioArray: audioSamples,
    decodeOptions: options
)

print(result?.text ?? "")
```

### 3.7. Real-time —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (AudioStreamTranscriber)

–î–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `AudioStreamTranscriber`:

```swift
import WhisperKit

class RealtimeTranscriptionManager {
    private var streamTranscriber: AudioStreamTranscriber?
    private var whisperKit: WhisperKit?
    
    func initialize() async throws {
        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º WhisperKit
        whisperKit = try await WhisperKit(
            WhisperKitConfig(model: "tiny-en")  // –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –¥–ª—è real-time
        )
        
        guard let kit = whisperKit,
              let audioEncoder = kit.audioEncoder as? AudioEncoder,
              let featureExtractor = kit.featureExtractor as? FeatureExtractor,
              let textDecoder = kit.textDecoder as? TextDecoder,
              let tokenizer = kit.tokenizer else {
            throw NSError(domain: "WhisperKit components not initialized", code: -1)
        }
        
        // –°–æ–∑–¥–∞–µ–º AudioStreamTranscriber
        streamTranscriber = AudioStreamTranscriber(
            audioEncoder: audioEncoder,
            featureExtractor: featureExtractor,
            segmentSeeker: kit.segmentSeeker,
            textDecoder: textDecoder,
            tokenizer: tokenizer,
            audioProcessor: kit.audioProcessor,
            decodingOptions: DecodingOptions(language: "ru"),
            requiredSegmentsForConfirmation: 2,  // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            silenceThreshold: 0.3,                // –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –¥–ª—è VAD
            useVAD: true,                         // –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Voice Activity Detection
            stateChangeCallback: { oldState, newState in
                // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–æ—Å—Ç–æ—è–Ω–∏—è
                DispatchQueue.main.async {
                    print("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: \(newState.confirmedSegments.map { $0.text }.joined())")
                    print("‚è≥ –ù–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: \(newState.unconfirmedSegments.map { $0.text }.joined())")
                    print("üé§ –¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç: \(newState.currentText)")
                }
            }
        )
    }
    
    // –ù–∞—á–∞—Ç—å real-time —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
    func startTranscription() async throws {
        try await streamTranscriber?.startStreamTranscription()
    }
    
    // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
    func stopTranscription() async {
        await streamTranscriber?.stopStreamTranscription()
    }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
let manager = RealtimeTranscriptionManager()
try await manager.initialize()
try await manager.startTranscription()  // –ù–∞—á–∏–Ω–∞–µ—Ç —Å–ª—É—à–∞—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω
// ... –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç ...
await manager.stopTranscription()      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
```

#### –°–æ—Å—Ç–æ—è–Ω–∏–µ AudioStreamTranscriber

```swift
public struct State {
    public var isRecording: Bool                          // –ò–¥–µ—Ç –ª–∏ –∑–∞–ø–∏—Å—å
    public var currentText: String                        // –¢–µ–∫—É—â–∏–π —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
    public var confirmedSegments: [TranscriptionSegment]  // –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    public var unconfirmedSegments: [TranscriptionSegment] // –ù–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    public var bufferEnergy: [Float]                      // –≠–Ω–µ—Ä–≥–∏—è –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä–∞ (–¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
    public var lastConfirmedSegmentEndSeconds: Float      // –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
}
```

### 3.8. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞

```swift
let (language, probabilities) = try await whisperKit.detectLanguage(
    audioPath: audioPath
)

print("–û–±–Ω–∞—Ä—É–∂–µ–Ω —è–∑—ã–∫: \(language)")
print("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
for (lang, prob) in probabilities.sorted(by: { $0.value > $1.value }).prefix(5) {
    print("  \(lang): \(String(format: "%.2f%%", prob * 100))")
}
```

### 3.9. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤

```swift
let audioPaths = [
    "recording1.m4a",
    "recording2.m4a",
    "recording3.m4a"
]

let results = await whisperKit.transcribeWithResults(
    audioPaths: audioPaths,
    decodeOptions: DecodingOptions(language: "ru")
)

for (index, result) in results.enumerated() {
    switch result {
    case .success(let transcriptions):
        print("–§–∞–π–ª \(index + 1): \(transcriptions.first?.text ?? "")")
    case .failure(let error):
        print("–û—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ \(index + 1): \(error.localizedDescription)")
    }
}
```

---

## ‚öôÔ∏è 4. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### 4.1. WhisperKitConfig - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

```swift
let config = WhisperKitConfig(
    // –ú–æ–¥–µ–ª—å
    model: "small-en",                    // –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    modelRepo: "argmaxinc/whisperkit-coreml",  // HuggingFace —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    modelFolder: nil,                     // –õ–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é
    
    // –ó–∞–≥—Ä—É–∑–∫–∞
    download: true,                       // –°–∫–∞—á–∏–≤–∞—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç
    load: true,                          // –ó–∞–≥—Ä—É–∂–∞—Ç—å –≤ –ø–∞–º—è—Ç—å —Å—Ä–∞–∑—É
    prewarm: true,                       // –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    
    // –í—ã—á–∏—Å–ª–µ–Ω–∏—è
    computeOptions: ModelComputeOptions(
        audioEncoderCompute: .cpuAndNeuralEngine,
        textDecoderCompute: .cpuAndGPU,
        melCompute: .cpuAndGPU
    ),
    
    // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    verbose: true,                        // –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
    logLevel: .info                      // –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
)

let whisperKit = try await WhisperKit(config)
```

### 4.2. ModelComputeOptions - –í—ã–±–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞

```swift
let computeOptions = ModelComputeOptions(
    audioEncoderCompute: .cpuAndNeuralEngine,  // Encoder –Ω–∞ Neural Engine
    textDecoderCompute: .cpuAndGPU,            // Decoder –Ω–∞ GPU
    melCompute: .cpuAndGPU,                    // Mel Spectrogram –Ω–∞ GPU
    prefillCompute: .cpuOnly                   // Prefill –Ω–∞ CPU
)
```

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:**
- `.cpuOnly` - —Ç–æ–ª—å–∫–æ CPU (–º–µ–¥–ª–µ–Ω–Ω–æ)
- `.cpuAndGPU` - CPU + GPU (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- `.cpuAndNeuralEngine` - CPU + Neural Engine (–±—ã—Å—Ç—Ä–æ –Ω–∞ Apple Silicon)
- `.all` - –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã

### 4.3. DecodingOptions - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

```swift
var options = DecodingOptions(
    // –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    verbose: false,                      // –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    task: .transcribe,                  // .transcribe –∏–ª–∏ .translate
    language: "ru",                     // –ö–æ–¥ —è–∑—ã–∫–∞ –∏–ª–∏ nil –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    
    // –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    wordTimestamps: true,               // –ú–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
    withoutTimestamps: false,           // –ë–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (–±—ã—Å—Ç—Ä–µ–µ)
    
    // –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (—Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å)
    temperature: 0.0,                   // 0.0 = –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ
    temperatureIncrementOnFallback: 0.2,
    temperatureFallbackCount: 5,
    
    // –ü–æ—Ä–æ–≥–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    compressionRatioThreshold: 2.4,     // –ü–æ—Ä–æ–≥ —Å–∂–∞—Ç–∏—è —Ç–µ–∫—Å—Ç–∞
    logProbThreshold: -1.0,             // –ü–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ª–æ–≥–∏—Ç–∞
    noSpeechThreshold: 0.6,             // –ü–æ—Ä–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏—à–∏–Ω—ã
    
    // –ß–∞–Ω–∫–∏–Ω–≥ (—Ä–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ)
    chunkingStrategy: .vad,             // –†–∞–∑–±–∏–≤–∫–∞ –ø–æ Voice Activity Detection
    
    // –ü—Ä–æ–º–ø—Ç –∏ –ø—Ä–µ—Ñ–∏–∫—Å
    promptTokens: nil,                  // –¢–æ–∫–µ–Ω—ã –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    prefixTokens: nil                   // –¢–æ–∫–µ–Ω—ã –ø—Ä–µ—Ñ–∏–∫—Å–∞
)

let result = try await whisperKit.transcribe(
    audioPath: audioPath,
    decodeOptions: options
)
```

### 4.4. –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —á–∞–Ω–∫–∏–Ω–≥–∞

–î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ (>30 —Å–µ–∫—É–Ω–¥):

```swift
var options = DecodingOptions()

// –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–ª–æ—Å–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
options.chunkingStrategy = .vad

// –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º
options.clipTimestamps = [0.0, 30.0, 60.0, 90.0]  // —Å–µ–∫—É–Ω–¥—ã

let result = try await whisperKit.transcribe(
    audioPath: longAudioPath,
    decodeOptions: options
)
```

---

## üìä 5. –†–∞–±–æ—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

### 5.1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ TranscriptionResult

```swift
struct TranscriptionResult {
    let text: String                           // –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    let segments: [TranscriptionSegment]       // –°–µ–≥–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∫–∞–º–∏
    let language: String                       // –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —è–∑—ã–∫
    let timings: TranscriptionTimings          // –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
}
```

### 5.2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ TranscriptionSegment

```swift
struct TranscriptionSegment {
    let id: Int                    // ID —Å–µ–≥–º–µ–Ω—Ç–∞
    let seek: Int                  // –ü–æ–∑–∏—Ü–∏—è –ø–æ–∏—Å–∫–∞
    let start: Float               // –ù–∞—á–∞–ª–æ (—Å–µ–∫—É–Ω–¥—ã)
    let end: Float                 // –ö–æ–Ω–µ—Ü (—Å–µ–∫—É–Ω–¥—ã)
    let text: String               // –¢–µ–∫—Å—Ç —Å–µ–≥–º–µ–Ω—Ç–∞
    let tokens: [Int]              // –¢–æ–∫–µ–Ω—ã
    let temperature: Float         // –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    let avgLogprob: Float         // –°—Ä–µ–¥–Ω—è—è –ª–æ–≥-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
    let compressionRatio: Float   // –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è
    let noSpeechProb: Float       // –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ä–µ—á–∏
}
```

### 5.3. –ü—Ä–∏–º–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

#### –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞

```swift
let result = try await whisperKit.transcribe(audioPath: audioPath)
let fullText = result?.text ?? ""
print(fullText)
```

#### –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤

```swift
if let segments = result?.segments {
    for (index, segment) in segments.enumerated() {
        print("–°–µ–≥–º–µ–Ω—Ç \(index + 1):")
        print("  –í—Ä–µ–º—è: \(segment.start)s - \(segment.end)s")
        print("  –¢–µ–∫—Å—Ç: \(segment.text)")
        print("  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ—á–∏: \(String(format: "%.2f%%", (1 - segment.noSpeechProb) * 100))")
    }
}
```

#### –°–æ–∑–¥–∞–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (SRT —Ñ–æ—Ä–º–∞—Ç)

```swift
func generateSRT(from result: TranscriptionResult?) -> String {
    guard let segments = result?.segments else { return "" }
    
    var srtContent = ""
    for (index, segment) in segments.enumerated() {
        let startTime = formatSRTTime(segment.start)
        let endTime = formatSRTTime(segment.end)
        
        srtContent += "\(index + 1)\n"
        srtContent += "\(startTime) --> \(endTime)\n"
        srtContent += "\(segment.text.trimmingCharacters(in: .whitespaces))\n\n"
    }
    
    return srtContent
}

func formatSRTTime(_ seconds: Float) -> String {
    let hours = Int(seconds) / 3600
    let minutes = (Int(seconds) % 3600) / 60
    let secs = Int(seconds) % 60
    let millis = Int((seconds - Float(Int(seconds))) * 1000)
    
    return String(format: "%02d:%02d:%02d,%03d", hours, minutes, secs, millis)
}
```

---

## üíº 6. –ü–æ–ª–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### 6.1. –ú–µ–Ω–µ–¥–∂–µ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–∫–ª–∞—Å—Å)

```swift
import WhisperKit
import AVFoundation
import Combine

class TranscriptionManager: ObservableObject {
    @Published var isLoading = false
    @Published var transcriptionText = ""
    @Published var progress: Double = 0.0
    @Published var error: Error?
    
    private var whisperKit: WhisperKit?
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperKit
    func initialize(model: String = "small-en") async {
        isLoading = true
        defer { isLoading = false }
        
        do {
            let config = WhisperKitConfig(
                model: model,
                verbose: true,
                prewarm: true
            )
            whisperKit = try await WhisperKit(config)
        } catch {
            self.error = error
            print("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: \(error)")
        }
    }
    
    // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞
    func transcribe(audioPath: String, language: String = "ru") async {
        guard let kit = whisperKit else {
            self.error = NSError(domain: "WhisperKit –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", code: -1)
            return
        }
        
        isLoading = true
        transcriptionText = ""
        progress = 0.0
        defer { isLoading = false }
        
        do {
            var options = DecodingOptions()
            options.language = language
            options.wordTimestamps = true
            
            let result = try await kit.transcribe(
                audioPath: audioPath,
                decodeOptions: options,
                callback: { [weak self] progressUpdate in
                    DispatchQueue.main.async {
                        self?.progress = progressUpdate.fractionCompleted
                    }
                },
                segmentCallback: { [weak self] segments in
                    DispatchQueue.main.async {
                        let newText = segments.map { $0.text }.joined()
                        self?.transcriptionText += newText
                    }
                }
            )
            
            DispatchQueue.main.async {
                self.transcriptionText = result?.text ?? ""
            }
        } catch {
            DispatchQueue.main.async {
                self.error = error
            }
            print("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: \(error)")
        }
    }
    
    // –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
    func detectLanguage(audioPath: String) async -> String? {
        guard let kit = whisperKit else { return nil }
        
        do {
            let (language, _) = try await kit.detectLanguage(audioPath: audioPath)
            return language
        } catch {
            self.error = error
            return nil
        }
    }
}
```

### 6.2. SwiftUI View —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π

```swift
import SwiftUI

struct TranscriptionView: View {
    @StateObject private var manager = TranscriptionManager()
    @State private var selectedAudioURL: URL?
    @State private var showFilePicker = false
    
    var body: some View {
        NavigationView {
            VStack(spacing: 20) {
                // –ö–Ω–æ–ø–∫–∞ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞
                Button(action: { showFilePicker = true }) {
                    Label("–í—ã–±—Ä–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª", systemImage: "doc.badge.plus")
                        .frame(maxWidth: .infinity)
                        .padding()
                        .background(Color.blue)
                        .foregroundColor(.white)
                        .cornerRadius(10)
                }
                .padding()
                
                // –ü—Ä–æ–≥—Ä–µ—Å—Å
                if manager.isLoading {
                    VStack {
                        ProgressView(value: manager.progress)
                            .progressViewStyle(LinearProgressViewStyle())
                        Text("–û–±—Ä–∞–±–æ—Ç–∫–∞: \(Int(manager.progress * 100))%")
                            .font(.caption)
                    }
                    .padding()
                }
                
                // –†–µ–∑—É–ª—å—Ç–∞—Ç
                ScrollView {
                    Text(manager.transcriptionText)
                        .padding()
                        .frame(maxWidth: .infinity, alignment: .leading)
                }
                .background(Color.gray.opacity(0.1))
                .cornerRadius(10)
                .padding()
                
                Spacer()
            }
            .navigationTitle("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ä–µ—á–∏")
            .fileImporter(
                isPresented: $showFilePicker,
                allowedContentTypes: [.audio],
                onCompletion: handleFileSelection
            )
            .task {
                await manager.initialize()
            }
        }
    }
    
    private func handleFileSelection(_ result: Result<URL, Error>) {
        switch result {
        case .success(let url):
            selectedAudioURL = url
            Task {
                await manager.transcribe(audioPath: url.path)
            }
        case .failure(let error):
            print("–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞: \(error)")
        }
    }
}
```

### 6.3. –ó–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è

```swift
import AVFoundation
import WhisperKit

class MicrophoneRecorder: NSObject, ObservableObject {
    @Published var isRecording = false
    @Published var transcriptionText = ""
    
    private var audioEngine: AVAudioEngine?
    private var recordedSamples: [Float] = []
    private var whisperKit: WhisperKit?
    
    override init() {
        super.init()
        setupAudioEngine()
    }
    
    func initialize() async {
        do {
            whisperKit = try await WhisperKit(
                WhisperKitConfig(model: "tiny-en")  // –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å –¥–ª—è real-time
            )
        } catch {
            print("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: \(error)")
        }
    }
    
    private func setupAudioEngine() {
        audioEngine = AVAudioEngine()
        let inputNode = audioEngine!.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }
    }
    
    func startRecording() {
        recordedSamples.removeAll()
        
        do {
            try AVAudioSession.sharedInstance().setCategory(.record, mode: .measurement)
            try AVAudioSession.sharedInstance().setActive(true)
            try audioEngine?.start()
            isRecording = true
        } catch {
            print("–û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏: \(error)")
        }
    }
    
    func stopRecording() async {
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        isRecording = false
        
        // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        await transcribeRecordedAudio()
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData else { return }
        let frameLength = Int(buffer.frameLength)
        
        let samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameLength))
        recordedSamples.append(contentsOf: samples)
    }
    
    private func transcribeRecordedAudio() async {
        guard let kit = whisperKit, !recordedSamples.isEmpty else { return }
        
        // –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–æ 16000 Hz (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        let resampledSamples = resample(recordedSamples, to: 16000)
        
        do {
            let result = try await kit.transcribe(
                audioArray: resampledSamples,
                decodeOptions: DecodingOptions(language: "ru")
            )
            
            DispatchQueue.main.async {
                self.transcriptionText = result?.text ?? ""
            }
        } catch {
            print("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: \(error)")
        }
    }
    
    private func resample(_ samples: [Float], to targetRate: Int) -> [Float] {
        // –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥ (–¥–ª—è production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ vDSP)
        return samples
    }
}
```

### 6.4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞

```swift
import AVFoundation
import WhisperKit

class VideoTranscriber {
    private var whisperKit: WhisperKit?
    
    func initialize() async throws {
        whisperKit = try await WhisperKit(
            WhisperKitConfig(model: "small-en")
        )
    }
    
    func transcribeVideo(url: URL) async throws -> TranscriptionResult? {
        // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
        let audioURL = try await extractAudio(from: url)
        
        // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ
        guard let kit = whisperKit else {
            throw NSError(domain: "WhisperKit –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", code: -1)
        }
        
        return try await kit.transcribe(audioPath: audioURL.path)
    }
    
    private func extractAudio(from videoURL: URL) async throws -> URL {
        let asset = AVAsset(url: videoURL)
        
        guard let exportSession = AVAssetExportSession(
            asset: asset,
            presetName: AVAssetExportPresetAppleM4A
        ) else {
            throw NSError(domain: "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å export session", code: -1)
        }
        
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("m4a")
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .m4a
        
        await exportSession.export()
        
        if exportSession.status == .completed {
            return outputURL
        } else {
            throw exportSession.error ?? NSError(domain: "–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞", code: -1)
        }
    }
}
```

---

## ‚ö° 7. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### 7.1. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

```swift
func selectOptimalModel(for device: String) -> String {
    let deviceName = device.lowercased()
    
    if deviceName.contains("iphone 15 pro") || deviceName.contains("iphone 16") {
        return "medium-en"  // –ú–æ—â–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    } else if deviceName.contains("iphone 13") || deviceName.contains("iphone 14") {
        return "small-en"   // –°—Ä–µ–¥–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    } else {
        return "tiny-en"    // –°—Ç–∞—Ä—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
let deviceModel = UIDevice.current.model
let optimalModel = selectOptimalModel(for: deviceModel)
let whisperKit = try await WhisperKit(WhisperKitConfig(model: optimalModel))
```

### 7.2. –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

```swift
class AppDelegate: UIResponder, UIApplicationDelegate {
    var whisperKit: WhisperKit?
    
    func application(
        _ application: UIApplication,
        didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?
    ) -> Bool {
        // –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ–Ω–µ
        Task {
            do {
                let config = WhisperKitConfig(
                    model: "small-en",
                    prewarm: true,  // –í–∞–∂–Ω–æ!
                    load: true
                )
                whisperKit = try await WhisperKit(config)
                print("‚úÖ WhisperKit –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ WhisperKit: \(error)")
            }
        }
        
        return true
    }
}
```

### 7.3. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

```swift
// –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ
func isModelDownloaded(modelName: String) -> Bool {
    let modelPath = FileManager.default.urls(for: .cachesDirectory, in: .userDomainMask)[0]
        .appendingPathComponent("huggingface")
        .appendingPathComponent("models")
        .appendingPathComponent("argmaxinc--whisperkit-coreml")
        .appendingPathComponent("openai_whisper-\(modelName)")
    
    return FileManager.default.fileExists(atPath: modelPath.path)
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
if isModelDownloaded(modelName: "small-en") {
    print("–ú–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é")
}
```

### 7.4. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ

```swift
// –î–ª—è —Ñ–∞–π–ª–æ–≤ > 10 –º–∏–Ω—É—Ç –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–∞–Ω–∫–∏–Ω–≥
var options = DecodingOptions()
options.chunkingStrategy = .vad  // –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–ª–æ—Å–∞

// –û—Ç–∫–ª—é—á–∏—Ç–µ –º–µ—Ç–∫–∏ —Å–ª–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
options.wordTimestamps = false

// –£–≤–µ–ª–∏—á—å—Ç–µ concurrentWorkerCount
options.concurrentWorkerCount = 4

let result = try await whisperKit.transcribe(
    audioPath: longAudioPath,
    decodeOptions: options
)
```

### 7.5. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

```swift
func printMemoryUsage() {
    var info = mach_task_basic_info()
    var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
    
    let kerr: kern_return_t = withUnsafeMutablePointer(to: &info) {
        $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
            task_info(mach_task_self_, task_flavor_t(MACH_TASK_BASIC_INFO), $0, &count)
        }
    }
    
    if kerr == KERN_SUCCESS {
        let usedMB = Double(info.resident_size) / 1024.0 / 1024.0
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: \(String(format: "%.2f", usedMB)) MB")
    }
}

// –í—ã–∑–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
printMemoryUsage()
```

---

## üåç 8. –†–∞–±–æ—Ç–∞ —Å —è–∑—ã–∫–∞–º–∏

### 8.1. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏

WhisperKit –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **100+ —è–∑—ã–∫–æ–≤** –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ multilingual –º–æ–¥–µ–ª–µ–π (`large-v3`, `distil-large-v3`).

**–û—Å–Ω–æ–≤–Ω—ã–µ —è–∑—ã–∫–∏:**
- –†—É—Å—Å–∫–∏–π: `ru`
- –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: `en`
- –ò—Å–ø–∞–Ω—Å–∫–∏–π: `es`
- –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π: `fr`
- –ù–µ–º–µ—Ü–∫–∏–π: `de`
- –ö–∏—Ç–∞–π—Å–∫–∏–π: `zh`
- –Ø–ø–æ–Ω—Å–∫–∏–π: `ja`
- –ö–æ—Ä–µ–π—Å–∫–∏–π: `ko`
- –ê—Ä–∞–±—Å–∫–∏–π: `ar`
- –•–∏–Ω–¥–∏: `hi`

[–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py)

### 8.2. –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞

```swift
var options = DecodingOptions()
options.language = nil          // –ù–µ —É–∫–∞–∑—ã–≤–∞–µ–º —è–∑—ã–∫
options.detectLanguage = true   // –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ

let result = try await whisperKit.transcribe(
    audioPath: audioPath,
    decodeOptions: options
)

print("–û–ø—Ä–µ–¥–µ–ª—ë–Ω —è–∑—ã–∫: \(result?.language ?? "unknown")")
```

### 8.3. –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π

```swift
var options = DecodingOptions()
options.task = .translate  // –ü–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
options.language = "ru"    // –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫

let result = try await whisperKit.transcribe(
    audioPath: russianAudioPath,
    decodeOptions: options
)

print("–ü–µ—Ä–µ–≤–æ–¥: \(result?.text ?? "")")
```

### 8.4. –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è

```swift
func transcribeMultilingual(audioPaths: [String]) async {
    let whisperKit = try! await WhisperKit(
        WhisperKitConfig(model: "large-v3")  // Multilingual –º–æ–¥–µ–ª—å
    )
    
    for path in audioPaths {
        // –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫
        let (language, _) = try! await whisperKit.detectLanguage(audioPath: path)
        print("–û–±–Ω–∞—Ä—É–∂–µ–Ω —è–∑—ã–∫: \(language)")
        
        // –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º —è–∑—ã–∫–æ–º
        var options = DecodingOptions()
        options.language = language
        
        let result = try! await whisperKit.transcribe(
            audioPath: path,
            decodeOptions: options
        )
        
        print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è [\(language)]: \(result?.text ?? "")")
    }
}
```

---

## üö® 9. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

### 9.1. –¢–∏–ø—ã –æ—à–∏–±–æ–∫ WhisperKit

```swift
enum WhisperError: Error {
    case modelsUnavailable(String)
    case tokenizerUnavailable()
    case transcriptionFailed(String)
    case audioProcessingFailed(String)
    case decodingFailed(String)
}
```

### 9.2. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```swift
func safeTranscribe(audioPath: String) async -> String {
    do {
        let whisperKit = try await WhisperKit()
        let result = try await whisperKit.transcribe(audioPath: audioPath)
        return result?.text ?? "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
        
    } catch let error as WhisperError {
        switch error {
        case .modelsUnavailable(let message):
            print("–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: \(message)")
            return "–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"
            
        case .tokenizerUnavailable:
            print("–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return "–û—à–∏–±–∫–∞: –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º"
            
        case .transcriptionFailed(let message):
            print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: \(message)")
            return "–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"
            
        case .audioProcessingFailed(let message):
            print("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: \(message)")
            return "–û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª"
            
        case .decodingFailed(let message):
            print("–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: \(message)")
            return "–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"
        }
        
    } catch {
        print("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: \(error.localizedDescription)")
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
    }
}
```

### 9.3. Retry –º–µ—Ö–∞–Ω–∏–∑–º

```swift
func transcribeWithRetry(
    audioPath: String,
    maxAttempts: Int = 3
) async -> TranscriptionResult? {
    var attempt = 0
    var lastError: Error?
    
    while attempt < maxAttempts {
        do {
            let whisperKit = try await WhisperKit()
            let result = try await whisperKit.transcribe(audioPath: audioPath)
            return result
            
        } catch {
            lastError = error
            attempt += 1
            print("–ü–æ–ø—ã—Ç–∫–∞ \(attempt) –Ω–µ —É–¥–∞–ª–∞—Å—å: \(error)")
            
            if attempt < maxAttempts {
                try? await Task.sleep(nanoseconds: 2_000_000_000)  // 2 —Å–µ–∫—É–Ω–¥—ã
            }
        }
    }
    
    print("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: \(lastError?.localizedDescription ?? "unknown")")
    return nil
}
```

---

## ‚úÖ 10. Best Practices

### 10.1. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏

```swift
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –í—ã–±–æ—Ä –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏
let realtimeKit = try await WhisperKit(WhisperKitConfig(model: "tiny-en"))  // Real-time
let accurateKit = try await WhisperKit(WhisperKitConfig(model: "small-en")) // –ë–∞–ª–∞–Ω—Å
let preciseKit = try await WhisperKit(WhisperKitConfig(model: "large-v3"))  // –¢–æ—á–Ω–æ—Å—Ç—å

// ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ large-v3 –¥–ª—è real-time
let slowKit = try await WhisperKit(WhisperKitConfig(model: "large-v3"))  // –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ!
```

### 10.2. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º

```swift
class TranscriptionService {
    private var whisperKit: WhisperKit?
    
    // ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    func initialize() async {
        guard whisperKit == nil else { return }  // –ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ
        
        whisperKit = try? await WhisperKit(
            WhisperKitConfig(model: "small-en", prewarm: true)
        )
    }
    
    // ‚úÖ –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞
    func transcribe(audioPath: String) async -> String? {
        guard let kit = whisperKit else {
            await initialize()
            guard let kit = whisperKit else { return nil }
            return try? await kit.transcribe(audioPath: audioPath)?.text
        }
        
        return try? await kit.transcribe(audioPath: audioPath)?.text
    }
    
    // ‚úÖ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    func cleanup() async {
        await whisperKit?.unloadModels()
        whisperKit = nil
    }
}
```

### 10.3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫

```swift
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏
func getOptionsForUseCase(_ useCase: UseCase) -> DecodingOptions {
    var options = DecodingOptions()
    
    switch useCase {
    case .realtime:
        options.temperature = 0.0
        options.wordTimestamps = false
        options.withoutTimestamps = true
        
    case .subtitles:
        options.wordTimestamps = true
        options.temperature = 0.0
        
    case .meeting:
        options.chunkingStrategy = .vad
        options.wordTimestamps = true
        
    case .voiceNote:
        options.temperature = 0.0
        options.compressionRatioThreshold = 2.4
    }
    
    return options
}

enum UseCase {
    case realtime, subtitles, meeting, voiceNote
}
```

### 10.4. –†–∞–±–æ—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏

```swift
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
func transcribeLargeFile(audioPath: String) async -> TranscriptionResult? {
    var options = DecodingOptions()
    options.chunkingStrategy = .vad       // –†–∞–∑–±–∏–≤–∫–∞ –ø–æ VAD
    options.wordTimestamps = false        // –û—Ç–∫–ª—é—á–∏—Ç—å –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    options.concurrentWorkerCount = 4     // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    
    return try? await whisperKit.transcribe(
        audioPath: audioPath,
        decodeOptions: options
    )
}

// ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: –ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
func transcribeLargeFileSlow(audioPath: String) async -> TranscriptionResult? {
    return try? await whisperKit.transcribe(audioPath: audioPath)
}
```

### 10.5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–π

```swift
class SafeTranscriber {
    private var currentTask: Task<Void, Never>?
    
    func transcribe(audioPath: String) {
        // –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –∑–∞–¥–∞—á—É
        currentTask?.cancel()
        
        currentTask = Task {
            do {
                let result = try await whisperKit.transcribe(audioPath: audioPath)
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ –æ—Ç–º–µ–Ω–µ–Ω–∞ –∑–∞–¥–∞—á–∞
                guard !Task.isCancelled else { return }
                
                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                print(result?.text ?? "")
                
            } catch {
                guard !Task.isCancelled else { return }
                print("–û—à–∏–±–∫–∞: \(error)")
            }
        }
    }
    
    func cancelTranscription() {
        currentTask?.cancel()
    }
}
```

### 10.6. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞

```swift
// ‚úÖ –í–∫–ª—é—á–∞–π—Ç–µ verbose –≤–æ –≤—Ä–µ–º—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
let debugConfig = WhisperKitConfig(
    model: "small-en",
    verbose: true,
    logLevel: .debug
)

// ‚úÖ –û—Ç–∫–ª—é—á–∞–π—Ç–µ –≤ production
let productionConfig = WhisperKitConfig(
    model: "small-en",
    verbose: false,
    logLevel: .error
)

// –ö–∞—Å—Ç–æ–º–Ω—ã–π –ª–æ–≥–≥–µ—Ä
whisperKit.loggingCallback { message in
    // –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∏–ª–∏ —Ñ–∞–π–ª
    print("[WhisperKit] \(message)")
}
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/argmaxinc/WhisperKit)
- [Swift Package Index](https://swiftpackageindex.com/argmaxinc/WhisperKit)
- [–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π](https://github.com/argmaxinc/WhisperKit/tree/main/Examples)

### –ú–æ–¥–µ–ª–∏
- [HuggingFace –º–æ–¥–µ–ª–∏](https://huggingface.co/argmaxinc/whisperkit-coreml)
- [–ë–µ–Ω—á–º–∞—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏](https://huggingface.co/spaces/argmaxinc/whisperkit-benchmarks)

### –°–æ–æ–±—â–µ—Å—Ç–≤–æ
- [Discord –∫–∞–Ω–∞–ª](https://discord.gg/G5F5GZGecC)
- [Twitter @argmaxinc](https://twitter.com/argmaxinc)

---

## üéØ –ö—Ä–∞—Ç–∫–∞—è —à–ø–∞—Ä–≥–∞–ª–∫–∞

```swift
// –ë–∞–∑–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
let kit = try await WhisperKit()

// –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞
let result = try await kit.transcribe(audioPath: "audio.mp3")
print(result?.text ?? "")

// –° –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
var options = DecodingOptions()
options.language = "ru"
options.wordTimestamps = true

let result = try await kit.transcribe(
    audioPath: "audio.mp3",
    decodeOptions: options
)

// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
for segment in result?.segments ?? [] {
    print("[\(segment.start)s - \(segment.end)s]: \(segment.text)")
}

// –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
let (language, _) = try await kit.detectLanguage(audioPath: "audio.mp3")
print("–Ø–∑—ã–∫: \(language)")

// –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
options.task = .translate
let translation = try await kit.transcribe(audioPath: "audio.mp3", decodeOptions: options)
```

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞:** 1.0  
**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 18 –æ–∫—Ç—è–±—Ä—è 2025  
**–í–µ—Ä—Å–∏—è WhisperKit:** 0.14.0+

**–õ–∏—Ü–µ–Ω–∑–∏—è:** MIT License

---

*–≠—Ç–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ WhisperKit –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞ –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω–∏—è. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ GitHub.*

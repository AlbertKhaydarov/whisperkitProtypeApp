# Техническое задание: интеграция SwiftWhisper для real-time распознавания речи в iOS приложении

## 1. Цель проекта

Реализовать в мобильном приложении (UIKit, iOS 15+) функциональность real-time распознавания речи на устройстве с использованием библиотеки [SwiftWhisper](https://github.com/exPHAT/SwiftWhisper.git), основанной на `whisper.cpp`.

## 2. Основные функции

### 2.1. Загрузка и управление моделью Whisper

* При первом запуске приложения автоматически скачать модель, указанную в конфигурационном файле (JSON или plist).
* Пользователь может выбрать одну из трех моделей:

  * `tiny.en`
  * `base.en`
  * `small.en`
* Скачанная модель сохраняется в локальном хранилище
* При повторном запуске приложение должно использовать локально сохранённую модель без повторного скачивания.

### 2.2. Инициализация и прогрев модели

* Модель загружается и прогревается **при старте приложения** в фоне.
* Прогресс прогрева отображается в `UIProgressView`.
* После завершения прогрева пользователь получает возможность сразу начать распознавание.
* Время до готовности должно быть минимальным.

### 2.3. Аудио и потоковая передача

* Подключение микрофона осуществляется через `AVAudioEngine`.
* Аудио должно конвертироваться в **16kHz PCM** (моно) согласно примеру с GitHub SwiftWhisper — *"Converting audio to 16kHz PCM"*.
* В процессе записи данные (аудиофреймы) передаются в модель для обработки в реальном времени.

### 2.4. Управление записью и распознаванием

* Кнопка **Старт/Стоп** управляет процессом распознавания:

  * При нажатии **Старт**:

    * очищается текстовое поле
    * запускается аудиосессия и распознавание
  * При нажатии **Стоп**:

    * запись останавливается
    * отображается финальный текст
    * кнопка меняет состояние на **Старт**
* Во время активного распознавания частичные результаты добавляются в `UITextView` или `UILabel`.

### 2.5. Повторное использование

* При повторном запуске приложения:

  * использовать уже загруженную и прогретую модель.
  * обеспечить быстрый старт распознавания (<1 секунда задержки).

## 3. Архитектура и ограничения

* Язык: **Swift 6.0+**
* UI: **UIKit** (❌ SwiftUI запрещён)
* ❌ Не использовать Combine, NotificationCenter, closures.
* ✅ Использовать делегаты и async/await.
* ✅ Безопасная работа с опционалами, без force unwrap (`!`).
* ✅ Чистая архитектура **MVP**.
* ✅ Минимум зависимостей, только SwiftWhisper и AVFoundation.
* ✅ Потокобезопасность: все операции с моделью и аудио — через `actor` или `DispatchQueue`.

## 4. Структура проекта

```
SwiftWhisperDemoApp/
├── AppDelegate.swift
├── SceneDelegate.swift
├── Config/
│   └── whisper_config.json
├── Managers/
│   ├── WhisperModelManager.swift      // загрузка и прогрев модели
│   ├── AudioRecordingManager.swift    // запись и преобразование аудио
│   └── WhisperTranscriptionManager.swift // взаимодействие с SwiftWhisper
├── Modules/
│   └── Recognition/
│       ├── RecognitionViewController.swift
│       ├── RecognitionPresenter.swift
│       └── RecognitionView.swift
└── Views/
    └── Components/
        ├── ProgressBarView.swift
        └── StartStopButton.swift
```

## 5. Логика взаимодействия компонентов

| Компонент                       | Ответственность                                                                       |
| ------------------------------- | ------------------------------------------------------------------------------------- |
| **WhisperModelManager**         | Загрузка и кэширование модели Whisper, инициализация и прогрев.                       |
| **AudioRecordingManager**       | Управление `AVAudioEngine`, конвертация в 16kHz PCM.                                  |
| **WhisperTranscriptionManager** | Подключение к SwiftWhisper API, передача аудиофреймов, получение текстовых сегментов. |
| **RecognitionPresenter**        | Логика бизнес-процесса: связь между ViewController и менеджерами.                     |
| **RecognitionViewController**   | Управление UI (кнопка, текст, прогресс).                                              |

## 6. UI Требования

* Минималистичный экран:

  * Кнопка **Старт / Стоп** (изменяет цвет и текст в зависимости от состояния).
  * `UIProgressView` для отображения прогрева модели.
  * `UITextView` для отображения результатов распознавания (реалтайм + финальный текст).

## 7. Дополнительные требования

* Отображение ошибок (модель не загружена, микрофон недоступен и т.п.) через `UIAlertController`.
* Логирование этапов (инициализация, прогрев, старт, стоп) через `os.Logger`.
* Все сетевые операции — async/await с `URLSession`.
* Поддержка офлайн-режима (без интернет-подключения после скачивания модели).

## 8. Критерии приёмки

* Приложение загружает и кэширует модель при первом запуске.
* Прогрев модели отображается в UI с прогрессом.
* Распознавание речи начинается после нажатия Старт и отображает промежуточные результаты.
* После Стоп показывается финальный текст и аудиосессия корректно завершается.
* Повторный запуск происходит без задержек и скачивания модели.
* Код соответствует Swift 6, UIKit, MVP и техническим ограничениям.

Функциональные требования (детально)
1) Скачивание модели

При первом запуске приложение проверяет наличие модели в Application Support/WhisperModels/<model>.bin. Если нет — скачивает модель выбранную в конфиге.

Использовать URLSession + URLSessionDownloadDelegate чтобы:

показывать прогресс скачивания (delegate callback didDownloadBytes → UI progress bar).

поддерживать resume (если соединение разорвано) — сохранять resumeData.

Проверять sha256 после скачивания, при несоответствии — удалить файл и попытаться повторно.

Скачивание должно происходить в фоне при первом запуске (но не блокировать UI) — но нельзя просить пользователя ждать: UI должен показывать прогресс и разрешать отмену.

2) Загрузка и прогрев модели при запуске

При старте приложения (или при возвращении из background), если файл модели есть — загрузить модель в память и выполнить прогрев:

Загрузка: Whisper(fromFileURL: modelURL) (внутри — выделение ресурсов). 
GitHub

Прогрев: выполнить короткую транскрипцию «нулевого»/тишинного буфера / короткого тестового входа для инициализации внутренних буферов и JIT-подобных структур.

Прогресс прогрева должен отдаваться через WhisperServiceDelegate в диапазоне 0.0–1.0 для отображения в UIProgressView.

Требование: чтобы пользователь мог нажать Start сразу после запуска — если прогрев ещё идёт, приложение должно:

запускать захват микрофона и отправлять буферы в очередь транскрибера, и как только модель готова, начать обрабатывать накопленные небольшие буферы (не терять первые N секунд).

альтернативно: при недостаточно прогретой модели показывать индикатор «включается» и не блокировать UI. Главное — минимальная задержка и прозрачная индикация прогресса.

3) Подключение микрофона и передача 16kHz PCM

AudioCaptureManager:

Конфигурировать AVAudioSession для .playAndRecord/.record и подходящих режимов; запрос permission AVAudioSession.sharedInstance().requestRecordPermission.

Использовать AVAudioEngine + AVAudioInputNode и AVAudioConverter для конвертации в моно 16kHz Float32 PCM (или Int16 в зависимости от SwiftWhisper API — в README ожидаются float массивы/16kHz PCM). README показывает 16kHz PCM как array of Floats / 16bit WAV conversion — можно использовать Float samples normalized [-1..1] или Int16 as needed. 
GitHub

Буферизация: агрегировать аудио в фреймы соответствующего размера, отправлять в WhisperService методом append(audioFrames: [Float]) или process(audioFrame: AudioFrame).

Все публичные события — через AudioCaptureDelegate (no closures).

Пример архитектуры делегата:

protocol AudioCaptureDelegate: AnyObject {
    func audioCapture(_ manager: AudioCaptureManager, didProducePCM frames: [Float])
    func audioCaptureDidStart(_ manager: AudioCaptureManager)
    func audioCaptureDidStop(_ manager: AudioCaptureManager)
    func audioCapture(_ manager: AudioCaptureManager, didFail error: Error)
}

4) UX: Start / Stop / текстовое поле

UI элементы:

Кнопка Start (при нажатии → начинает аудиозахват; кнопка меняется на Stop).

При Stop → останавливается аудиозахват, Whisper финализирует транскрипцию (получаем финальный текст), кнопка снова Start.

UITextView/UILabel с нарастающим распознанным текстом: новые сегменты добавляются последовательно (append).

При повторном нажатии Start → старые тексты очищаются, начинается новая сессия.

Поведение:

Пока идёт распознавание — обновление текста должно происходить инкрементально (через WhisperServiceDelegate метод didProcessNewSegments).

На Stop — вызываем whisper.finalize() (если есть) → получаем didCompleteWithSegments.

UI блоки: если модель ещё прогревается — отображать прогресс; но разрешить Start. В случае, если модель не загружена совсем — кнопка Start должна инициализировать скачивание и показать прогресс.

5) Re-start / reset

При повторном нажатии Start:

AudioCaptureManager очищает внутренние буферы и начинает новую сессию.

WhisperService очищает текущие временные сегменты и начинает новую сессию обработки (API: startNewSession()).

UI очищает текстовое поле.

6) Быстрота готовности (performance)

Предложения:

Прогрев модели: прогон короткого (1–2 с) тишинного/белого шума фрагмента для «разогрева» внутренних структур.

Поддержать загрузку модели в фоновом потоке (actor/Task), не блокируя main thread.

Кэшировать результаты и статус прогрева (последняя успешная инициализация), чтобы при quick relaunch использовать уже готовую модель (если процесс приложения не был убит).

7) Портируемость и модульность

Код оформить как Swift Package или отдельный framework, с чётким API:

ModelManager API публичные методы: func ensureModelDownloaded(named:) async throws, func modelURL(named:) -> URL?, func removeModel(named:) async throws

WhisperService публичные: func loadModel(from url: URL) async throws, func startSession() throws, func stopSession() async throws, func appendAudioFrames(_ frames: [Float]) async throws

Все callbacks через делегат-протоколы.

Не смешивать UI и сервисы: UI использует только публичные методы/делегаты.

Интерфейсы и протоколы (примерные подписи)

Следующие интерфейсы — рекомендуемый контракт. Используйте делегаты, акторы и async/await — без замыканий.

// MARK: - ModelManager (actor)
actor ModelManager {
    enum ModelName: String { case tiny_en = "tiny.en", base_en = "base.en", small_en = "small.en" }

    // Проверить и при необходимости скачать модель
    func ensureModelAvailable(_ model: ModelName) async throws -> URL

    // Получить локальный URL (nil если нет)
    func localModelURL(_ model: ModelName) -> URL?

    // Удалить модель
    func removeModel(_ model: ModelName) async throws

    // Подписка на прогресс скачивания — через делегат или Notification UI (но лучше delegate)
}

// MARK: - WhisperServiceDelegate
protocol WhisperServiceDelegate: AnyObject {
    func whisperService(_ service: WhisperService, didUpdateWarmupProgress progress: Double) // 0..1
    func whisperService(_ service: WhisperService, didReceiveSegments segments: [Segment], atIndex index: Int)
    func whisperService(_ service: WhisperService, didCompleteWithSegments segments: [Segment])
    func whisperService(_ service: WhisperService, didFailWith error: Error)
}

// MARK: - WhisperService
class WhisperService {
    weak var delegate: WhisperServiceDelegate?

    // Инициализация/загрузка модели (async)
    func loadModel(at fileURL: URL) async throws

    // Прогрев модели — запускает internal warmup и отсылает прогресс в delegate
    func warmupModel() async throws

    // Начать новую сессию распознавания
    func startNewSession() throws

    // Остановить/финализировать сессию (получить финальный текст)
    func stopSession() async throws

    // Добавить аудиофреймы (16kHz PCM Float)
    func appendAudioFrames(_ frames: [Float]) async throws
}


Segment — struct, как в SwiftWhisper (timestamp, text, confidence).

(При реализации — использовать фактические типы из SwiftWhisper.)

UI: ViewController (пример поведения)

TranscriptionViewController:

Views: UIButton startStopButton, UIProgressView modelWarmupProgress, UITextView transcriptView.

Делегирует Start/Stop команды к AudioCaptureManager и WhisperService.

Подписывается на WhisperServiceDelegate и AudioCaptureDelegate.

На new segments — append в текстовое поле (с учётом потокобезопасности — main thread).

Сетевые детали и безопасность

Сертификатные требования: использовать HTTPS, validate server cert (по умолчанию URLSession делает это).

Сохранение моделей: FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask) → WhisperModels.

Контроль целостности: sha256 контрольная сумма после загрузки.

Версионирование: если конфиг модели меняется (новая версия), старые файлы имеют версии в имени <model>-vX.bin.

Ошибки и recovery

Ошибки при скачивании: retry с экспоненциальной задержкой, пользователю — понятная ошибка + кнопка Retry.

Ошибки при инициализации модели: удалять файл и пометить как corrupt; предлагать загрузить заново.

При нехватке памяти — graceful fallback: прервать прогрев и показать ошибку; приложение должно не падать.

Логирование: подробные логи только для ключевых этапов для последующего анализа.

Battery: оптимизировать AVAudioSession и отключать ненужную обработку при Stop.

Privacy: запрос на доступ к микрофону и пояснение в Info.plist (NSMicrophoneUsageDescription).

Memory: выгружать модель/ресурсы при получении сообщения о низкой памяти, поддержать перераспределение.


